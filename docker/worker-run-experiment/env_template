# TODO ssh for container, update env variables needed for each experiment
## SAMPLE VALUES- REPLACE WITH YOUR OWN
#Should be saved as ".env" when you are ready
# mlflow tracking uri: http server (ip specified by $MLIP ), port 5000
# note for docker env file, comments must be on their own line, and quotes are not
# processed. Thus, a="4" # comment gets parsed to a='"4" # comment'
# also it appears that env variables unfortunately don't get processed


# tracking ip can be retrieved with gcloud compute instances describe {instance_name}
# --zone={zone} --format='get(networkInterfaces[0].networkIP)'
# IP and port of mlflow tracking server with uri http://{IP}:{PORT}

# example is the default mlflow server running on localhost:5000 (127.0.0.1:5000)
MLFLOW_TRACKING_IP=127.0.0.1
MLFLOW_TRACKING_PORT=5000

# dataset used in experiment (must match name of directory in dataset path)
DATASET_NAME=my_dataset

# paths in container. default values should be fine, or you can change them.
# path in container to raw and processed data roots
CONTAINER_DATASET=/root/dataset/
CONTAINER_PROCESSED=/root/processed/

# temp dir for artifacts (saved here  before calling mlflow.log_artifact())
CONTAINER_ARTIFACT=/root/artifacts/

# path in container to mount experiment files (run_experiment.sh, etc)
CONTAINER_EXP=/root/exp

# docker image used to run experiment
DOCKER_IMAGE=container:latest

# paths on host machine, be careful not to use these in docker container
# (they will not work as ${variables} does not get parsed correctly)

# graph features:  
FEATURES=feature-name
# graph targets: candidate growth ratio 10 or greater
TARGETS=target-name
HOST_PROCESSED=${HOME}/processed-data/${DATASET_NAME}/${FEATURES}/${TARGETS}
HOST_DATASET=${HOME}/datasets/${DATASET_NAME}
