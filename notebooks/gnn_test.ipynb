{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from src.graphs import Graph\n",
    "from src.utils import batcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GATNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GATNet(torch.nn.Module):\n",
    "    def __init__(self, data, heads_layer1, \n",
    "               heads_layer2, dropout, dropout_alphas):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "        num_features = data.num_features\n",
    "        num_classes = 2  # hardcoded for now\n",
    "\n",
    "        self.conv1 = GATConv(in_channels=num_features, out_channels=8,\n",
    "                             heads=heads_layer1, concat=True, negative_slope=0.2, \n",
    "                             dropout=dropout_alphas)\n",
    "\n",
    "        self.conv2 = GATConv(in_channels=8*heads_layer1, out_channels=num_classes, \n",
    "                             heads=heads_layer2, concat=False, negative_slope=0.2,\n",
    "                             dropout=dropout_alphas)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x=data.x\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv1(x, data.edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, data.edge_index)\n",
    "      \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, mask):\n",
    "    \"\"\"\n",
    "    Single iteration of training\n",
    "    \"\"\"\n",
    "    # set training mode to True (enabling dropout, etc)\n",
    "    model.train()\n",
    "    \n",
    "    # make sure format of weights is correct\n",
    "    model.double()\n",
    "    \n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # get output of model, which is log-probability (log of softmax)\n",
    "    # note mask is not applied because message passing needs all nodes\n",
    "    log_softmax = model(data)\n",
    "    \n",
    "    labels = data.y # labels of each node\n",
    "    \n",
    "    # apply training mask\n",
    "    nll_loss = F.nll_loss(log_softmax[mask], labels[mask])\n",
    "    \n",
    "    # backprop- compute gradients\n",
    "    nll_loss.backward()\n",
    "    \n",
    "    # backprop- update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "def compute_accuracy(model, data, mask):\n",
    "    # set eval mode to True (disable dropout, etc)\n",
    "    model.eval()\n",
    "    \n",
    "    model.double()\n",
    "    \n",
    "    # get output of model\n",
    "    log_softmax = model(data)\n",
    "    \n",
    "    # get index of max value from softmax, equivalent to y pred\n",
    "    yp = log_softmax[mask].argmax(dim=1) \n",
    "    \n",
    "    \n",
    "    \n",
    "    return yp == data.y[mask]\n",
    "\n",
    "# run without gradient (faster)\n",
    "@torch.no_grad() \n",
    "def test(model, data):\n",
    "    return compute_accuracy(model, data, data.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_agg(g):\n",
    "    if g.graph_attr['candidate_growth_ratio'] > 10 and g.graph_attr['candidate_rgr'] > 2.5:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Path('..','data','candidate-grains-processed')\n",
    "data.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_paths = list(sorted(data.glob('*'))[-1].glob('*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(d):\n",
    "    d.x = (d.x - d.x.mean(dim=0))/d.x.std(dim=0)\n",
    "    d.edge_attr = (d.edge_attr - d.edge_attr.mean(dim=0)/d.edge_attr.std(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = [Graph.from_json(x) for x in json_paths[:200]]\n",
    "datasets = [g.to_pyg_dataset() for g in graphs]\n",
    "for g, d in zip(graphs, datasets):\n",
    "    y = np.zeros(len(g.nodes), np.int)\n",
    "    y[d.mask] = int(detect_agg(g))\n",
    "    d.y = torch.tensor(y, dtype=torch.long)\n",
    "    normalize_features(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch_geometric.data.Batch().from_data_list(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train: 0.6300, Loss: 0.7205\n",
      "Epoch: 010, Train: 0.6250, Loss: 0.6924\n",
      "Epoch: 015, Train: 0.6250, Loss: 0.6706\n",
      "Epoch: 020, Train: 0.6150, Loss: 0.6666\n",
      "Epoch: 025, Train: 0.6150, Loss: 0.6719\n",
      "Epoch: 030, Train: 0.6150, Loss: 0.6760\n",
      "Epoch: 035, Train: 0.6150, Loss: 0.6763\n",
      "Epoch: 040, Train: 0.6150, Loss: 0.6759\n",
      "Epoch: 045, Train: 0.6150, Loss: 0.6755\n",
      "Epoch: 050, Train: 0.6150, Loss: 0.6750\n"
     ]
    }
   ],
   "source": [
    "gat = GATNet(datasets[0], 4, 4, 0.5, 0.5)\n",
    "gat.double()\n",
    "\n",
    "\n",
    "#optimizer = torch.optim.Adam(gat.parameters(), lr=0.005, weight_decay=1e-3)\n",
    "optimizer = torch.optim.Adam(gat.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "log = 'Epoch: {:03d}, Train: {:.4f}, Loss: {:.4f}'#', Val: {:.4f}'\n",
    "for epoch in range(1, 51):\n",
    "    train(gat, batch, optimizer, batch.mask)\n",
    "    #for d in datasets:\n",
    "    #    train(gat, d, optimizer, d.mask)\n",
    "    if epoch % 5 == 0:\n",
    "        tests = [test(gat, d) for d in datasets]\n",
    "        losses = [F.nll_loss(gat(d)[d.mask], d.y[d.mask]).detach().numpy() for d in datasets]\n",
    "        \n",
    "        print(log.format(epoch, np.mean(tests), np.mean(losses)), )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_all = [list(x.glob('*.json')) for x in data.glob('*') if x.is_dir() and len(list(x.glob('*.json'))) > 500] \n",
    "temp = []\n",
    "[temp.extend(r) for r in runs_all]\n",
    "runs_all = sorted(temp)\n",
    "rs = np.random.RandomState(seed=3346665170)\n",
    "rs.shuffle(runs_all)\n",
    "from multiprocessing import get_context, Pool\n",
    "def load_wrapper(x):\n",
    "    from src.graphs import Graph\n",
    "    g = Graph.from_json(x)\n",
    "    d = g.to_pyg_dataset()\n",
    "    y = np.zeros(len(g.nodes), np.int)\n",
    "    y[d.mask] = int(detect_agg(g))\n",
    "    d.y = torch.tensor(y, dtype=torch.long)\n",
    "    return d\n",
    "\n",
    "#with Pool(processes=8) as p:\n",
    "#    datasets_large = p.map(load_wrapper, runs_all[:1000])\n",
    "\n",
    "datasets_large = list(map(load_wrapper, runs_all[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = batcher(datasets_large, batch_size=100, min_size=30)\n",
    "batches = [torch_geometric.data.Batch().from_data_list(b) for b in batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-661e2596a2df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-661e2596a2df>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/School/Research/Projects/AFRL_AGG/AGG_env/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-453bc543cd59>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'mask'"
     ]
    }
   ],
   "source": [
    "gat = GATNet(datasets[0], 4, 4, 0.5, 0.5)\n",
    "gat.double()\n",
    "\n",
    "\n",
    "#optimizer = torch.optim.Adam(gat.parameters(), lr=0.005, weight_decay=1e-3)\n",
    "optimizer = torch.optim.Adam(gat.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "log = 'Epoch: {:03d}, Train: {:.4f}, Loss: {:.4f}'#', Val: {:.4f}'\n",
    "for epoch in range(1, 51):\n",
    "    for batch in batches:\n",
    "        train(gat, batch, optimizer, batch.mask)\n",
    "    if epoch % 5 == 0:\n",
    "        # TODO fix these functions to work with multiple batches\n",
    "        tests = [test(gat, d) for d in batches[0]]\n",
    "        losses = [F.nll_loss(gat(d)[d.mask], d.y[d.mask]).detach().numpy() for d in batches]\n",
    "        \n",
    "        print(log.format(epoch, np.mean(tests), np.mean(losses)), )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[44182], edge_attr=[265142, 4], edge_index=[2, 265142], mask=[44182], x=[44182, 9], y=[44182])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
